p: 97
vocab_size: 97
d: 128
h: 4
n_layers: 2
train_frac: 0.7
batch_size: 128
lr: 0.001
weight_decay: 0.001
steps: 100000
eval_every: 200
seed: 0
device: auto
