p: 113
vocab_size: 113
d: 128
h: 4
n_layers: 1
train_frac: 0.4
batch_size: 128
lr: 0.001
weight_decay: 0.001
steps: 800000
eval_every: 200
seed: 0
device: auto
